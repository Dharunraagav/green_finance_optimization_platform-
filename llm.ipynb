{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting groq\n",
      "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting lxml>=3.1.0 (from python-docx)\n",
      "  Downloading lxml-5.3.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting typing-extensions>=4.9.0 (from python-docx)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting Pillow>=9.1 (from pdfplumber)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer>=2.0.0 (from pdfminer.six==20231228->pdfplumber)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20231228->pdfplumber)\n",
      "  Downloading cryptography-44.0.1-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from groq)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from groq)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from groq)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from groq)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting sniffio (from groq)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->groq)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->groq)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->groq)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->groq)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm0:01\u001b[0m\n",
      "\u001b[?25hDownloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-5.3.1-cp312-cp312-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (145 kB)\n",
      "Downloading cryptography-44.0.1-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: typing-extensions, sniffio, pypdfium2, pycparser, Pillow, lxml, idna, h11, distro, charset-normalizer, certifi, annotated-types, python-docx, pydantic-core, httpcore, cffi, anyio, pydantic, httpx, cryptography, pdfminer.six, groq, pdfplumber\n",
      "Successfully installed Pillow-11.1.0 annotated-types-0.7.0 anyio-4.8.0 certifi-2025.1.31 cffi-1.17.1 charset-normalizer-3.4.1 cryptography-44.0.1 distro-1.9.0 groq-0.18.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 lxml-5.3.1 pdfminer.six-20231228 pdfplumber-0.11.5 pycparser-2.22 pydantic-2.10.6 pydantic-core-2.27.2 pypdfium2-4.30.1 python-docx-1.1.2 sniffio-1.3.1 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx pdfplumber groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Information:\n",
      "### 1. Personal/Company Information\n",
      "- **Name**: Arjun Sharma\n",
      "- **Organization**: Not explicitly stated (e-commerce business)\n",
      "- **Industry**: E-commerce\n",
      "\n",
      "### 2. Credit Information\n",
      "- **CIBIL Score**: 785/900\n",
      "  - **Description**: Demonstrates responsible financial behavior with timely repayments on his housing loan and no overdue or pending loans against his name.\n",
      "\n",
      "### 3. Financial Information\n",
      "- **Loan Amount**: ₹10,00,000\n",
      "- **Annual Income**: ₹12,00,000\n",
      "- **Business Turnover**: ₹25,00,000 annually\n",
      "- **Monthly Expenses**: ₹60,000\n",
      "- **Savings**: Fixed deposits worth ₹5,00,000, savings account balance averaging ₹2,00,000, and multiple bank accounts with combined balances totaling ₹3,50,000\n",
      "\n",
      "### 4. Asset Information\n",
      "- **Residential Property**: Valued at ₹80,00,000\n",
      "- **Vehicles and Jewelry**: Worth ₹15,00,000\n",
      "- **Agricultural Land**: Valued at ₹20,00,000 (owned by his family)\n",
      "\n",
      "### 5. Employment and Business Experience\n",
      "- **Years of Experience as an Entrepreneur**: 6 years\n",
      "- **Number of Employees**: 10 individuals\n",
      "- **Business Growth**: Successfully grown his e-commerce business, scaling operations year-on-year\n",
      "\n",
      "### 6. ESG (Environmental, Social, and Governance) Information\n",
      "- **Environmental Impact**: Not explicitly mentioned\n",
      "- **Social Impact**: Contributes to employment (10 individuals) and potential positive impact on the community through business growth\n",
      "- **Governance**: Demonstrates prudent financial planning and stable income streams, indicating good governance practices\n",
      "\n",
      "### 7. Additional Information\n",
      "- **Digital Transactions**: Active use of digital wallets like Google Pay and PhonePe, with average monthly transactions amounting to ₹30,000\n",
      "- **Utility Payments**: Consistently paid on time over the past five years, showcasing disciplined financial habits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "\n",
    "# Initialize Groq client with your API key\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "# Function to extract text from DOCX\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        full_text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            full_text += page.extract_text()\n",
    "    return full_text\n",
    "\n",
    "# Function to extract information using Groq API\n",
    "def extract_information_with_groq(text, template):\n",
    "    # Prepare the prompt for Groq API\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with extracting financial and ESG-related information from the following text.\n",
    "    Use the provided template to structure the output. Fill in the fields based on the content of the text.\n",
    "    \n",
    "    Template:\n",
    "    {template}\n",
    "    \n",
    "    Text to analyze:\n",
    "    {text}\n",
    "    \n",
    "    Output the filled template with the extracted information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call Groq API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts structured information from unstructured text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_completion_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )\n",
    "    \n",
    "    # Stream the response\n",
    "    extracted_info = \"\"\n",
    "    for chunk in completion:\n",
    "        extracted_info += chunk.choices[0].delta.content or \"\"\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "# Main function to process the file\n",
    "def process_file(file_path, template):\n",
    "    # Check file type and extract text\n",
    "    if file_path.endswith('.docx'):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith('.pdf'):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please upload a DOCX or PDF file.\")\n",
    "    \n",
    "    # Extract information using Groq API\n",
    "    extracted_data = extract_information_with_groq(text, template)\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the comprehensive template\n",
    "    template = \"\"\"\n",
    "    ### 1. Personal/Company Information\n",
    "    - **Name**: [Insert Name]\n",
    "    - **Organization**: [Insert Organization Name]\n",
    "    - **Industry**: [Insert Industry Type]\n",
    "\n",
    "    ### 2. Credit Information\n",
    "    - **CIBIL Score**: [Insert CIBIL Score]\n",
    "      - **Description**: [Brief description or notes about the score]\n",
    "\n",
    "    ... (rest of the template)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Path to the uploaded file (DOCX or PDF)\n",
    "    file_path = \"/home/dharun/Desktop/llama/temp.pdf\"\n",
    "    \n",
    "    # Process the file and extract information\n",
    "    try:\n",
    "        extracted_info = process_file(file_path, template)\n",
    "        print(\"Extracted Information:\")\n",
    "        print(extracted_info)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The uploaded file does not contain relevant financial or ESG-related information.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "\n",
    "# Initialize Groq client with your API key\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "# Define the list of valid keywords/phrases based on your categories\n",
    "VALID_KEYWORDS = [\n",
    "    \"CIBIL Score\", \"Overdue\", \"Pending Loans\", \"Utility Payments\", \n",
    "    \"Electricity Bill\", \"Water Bill\", \"Digital Wallet\", \"Cost of Living\", \n",
    "    \"Annual Income\", \"Turnover\", \"Fixed Deposit\", \"Savings Investments\", \n",
    "    \"Assets\", \"Bank Balance\", \"Entrepreneur\", \"ESG\", \"Environmental Impact\", \n",
    "    \"Social Responsibility\", \"Governance\"\n",
    "]\n",
    "\n",
    "# Function to extract text from DOCX\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        full_text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            full_text += page.extract_text()\n",
    "    return full_text\n",
    "\n",
    "# Function to validate content based on keywords\n",
    "def validate_content(text):\n",
    "    # Check if any of the valid keywords are present in the text\n",
    "    for keyword in VALID_KEYWORDS:\n",
    "        if keyword.lower() in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to extract information using Groq API\n",
    "def extract_information_with_groq(text, template):\n",
    "    # Prepare the prompt for Groq API\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with extracting financial and ESG-related information from the following text.\n",
    "    Use the provided template to structure the output. Fill in the fields based on the content of the text.\n",
    "    \n",
    "    Template:\n",
    "    {template}\n",
    "    \n",
    "    Text to analyze:\n",
    "    {text}\n",
    "    \n",
    "    Output the filled template with the extracted information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call Groq API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts structured information from unstructured text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_completion_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )\n",
    "    \n",
    "    # Stream the response\n",
    "    extracted_info = \"\"\n",
    "    for chunk in completion:\n",
    "        extracted_info += chunk.choices[0].delta.content or \"\"\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "# Main function to process the file\n",
    "def process_file(file_path, template):\n",
    "    # Check file type and extract text\n",
    "    if file_path.endswith('.docx'):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith('.pdf'):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please upload a DOCX or PDF file.\")\n",
    "    \n",
    "    # Validate the content before proceeding\n",
    "    if not validate_content(text):\n",
    "        raise ValueError(\"The uploaded file does not contain relevant financial or ESG-related information.\")\n",
    "    \n",
    "    # Extract information using Groq API\n",
    "    extracted_data = extract_information_with_groq(text, template)\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the comprehensive template\n",
    "    template = \"\"\"\n",
    "    ### 1. Personal/Company Information\n",
    "    - **Name**: [Insert Name]\n",
    "    - **Organization**: [Insert Organization Name]\n",
    "    - **Industry**: [Insert Industry Type]\n",
    "\n",
    "    ### 2. Credit Information\n",
    "    - **CIBIL Score**: [Insert CIBIL Score]\n",
    "      - **Description**: [Brief description or notes about the score]\n",
    "\n",
    "    ... (rest of the template)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Path to the uploaded file (DOCX or PDF)\n",
    "    file_path = \"/home/dharun/Desktop/llama/A Personalized Approach to Post-Traumatic Stress Disorder 1 (1) (1).pdf\"\n",
    "    \n",
    "    # Process the file and extract information\n",
    "    try:\n",
    "        extracted_info = process_file(file_path, template)\n",
    "        print(\"Extracted Information:\")\n",
    "        print(extracted_info)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The uploaded file does not contain relevant financial or ESG-related information.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "\n",
    "# Initialize Groq client with your API key\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "# Define the list of valid keywords/phrases based on your categories\n",
    "VALID_KEYWORDS = [\n",
    "    \"CIBIL Score\", \"Overdue\", \"Pending Loans\", \"Utility Payments\", \n",
    "    \"Electricity Bill\", \"Water Bill\", \"Digital Wallet\", \"Cost of Living\", \n",
    "    \"Annual Income\", \"Turnover\", \"Fixed Deposit\", \"Savings Investments\", \n",
    "    \"Assets\", \"Bank Balance\", \"Entrepreneur\", \"ESG\", \"Environmental Impact\", \n",
    "    \"Social Responsibility\", \"Governance\"\n",
    "]\n",
    "\n",
    "# Define thresholds for each condition\n",
    "CONDITION_THRESHOLDS = {\n",
    "    \"CIBIL Score\": {\"max_score\": 2, \"good_threshold\": 750},\n",
    "    \"Overdue/Pending Loans\": {\"max_score\": 2, \"max_overdue\": 50000},\n",
    "    \"Utility Payments\": {\"max_score\": 1, \"on_time_ratio\": 0.9},\n",
    "    \"Digital Wallet Transactions\": {\"max_score\": 1, \"min_transactions\": 5},\n",
    "    \"Cost of Living vs Spending\": {\"max_score\": 1, \"savings_ratio\": 0.2},\n",
    "    \"Annual Income or Turnover\": {\"max_score\": 2, \"min_income\": 500000},\n",
    "    \"Fixed Deposit/Savings Investments\": {\"max_score\": 1, \"min_investment\": 100000},\n",
    "    \"Assets of Individual/Family\": {\"max_score\": 1, \"min_assets\": 500000},\n",
    "    \"Bank Balance & Multiple Accounts\": {\"max_score\": 1, \"min_balance\": 100000},\n",
    "    \"Entrepreneur Length of Employment\": {\"max_score\": 1, \"min_years\": 2},\n",
    "    \"ESG Related Information\": {\"max_score\": 1, \"min_initiatives\": 1}\n",
    "}\n",
    "\n",
    "# Function to extract text from DOCX\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        full_text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            full_text += page.extract_text()\n",
    "    return full_text\n",
    "\n",
    "# Function to validate content based on keywords\n",
    "def validate_content(text):\n",
    "    # Check if any of the valid keywords are present in the text\n",
    "    for keyword in VALID_KEYWORDS:\n",
    "        if keyword.lower() in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to extract information using Groq API\n",
    "def extract_information_with_groq(text, template):\n",
    "    # Prepare the prompt for Groq API\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with extracting financial and ESG-related information from the following text.\n",
    "    Use the provided template to structure the output. Fill in the fields based on the content of the text.\n",
    "    \n",
    "    Template:\n",
    "    {template}\n",
    "    \n",
    "    Text to analyze:\n",
    "    {text}\n",
    "    \n",
    "    Output the filled template with the extracted information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call Groq API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts structured information from unstructured text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_completion_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )\n",
    "    \n",
    "    # Stream the response and parse it into a dictionary\n",
    "    extracted_info = {}\n",
    "    current_key = None\n",
    "    for chunk in completion:\n",
    "        content = chunk.choices[0].delta.content or \"\"\n",
    "        lines = content.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if line.strip().endswith(\":\"):\n",
    "                # This is a key (e.g., \"CIBIL Score:\")\n",
    "                current_key = line.strip().rstrip(\":\")\n",
    "                extracted_info[current_key] = \"\"\n",
    "            elif current_key:\n",
    "                # This is a value for the current key\n",
    "                extracted_info[current_key] += line.strip()\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "# Function to calculate score for each condition\n",
    "def calculate_score(extracted_data):\n",
    "    total_score = 0\n",
    "    \n",
    "    # Example: CIBIL Score\n",
    "    cibil_score = int(extracted_data.get(\"CIBIL Score\", 0))\n",
    "    if cibil_score >= CONDITION_THRESHOLDS[\"CIBIL Score\"][\"good_threshold\"]:\n",
    "        total_score += CONDITION_THRESHOLDS[\"CIBIL Score\"][\"max_score\"]\n",
    "    \n",
    "    # Example: Overdue/Pending Loans\n",
    "    overdue_loans = int(extracted_data.get(\"Overdue/Pending Loans\", 0))\n",
    "    if overdue_loans <= CONDITION_THRESHOLDS[\"Overdue/Pending Loans\"][\"max_overdue\"]:\n",
    "        total_score += CONDITION_THRESHOLDS[\"Overdue/Pending Loans\"][\"max_score\"]\n",
    "    \n",
    "    # Example: Utility Payments\n",
    "    utility_payment_ratio = float(extracted_data.get(\"Utility Payments On-Time Ratio\", 0))\n",
    "    if utility_payment_ratio >= CONDITION_THRESHOLDS[\"Utility Payments\"][\"on_time_ratio\"]:\n",
    "        total_score += CONDITION_THRESHOLDS[\"Utility Payments\"][\"max_score\"]\n",
    "    \n",
    "    # Example: Digital Wallet Transactions\n",
    "    digital_wallet_transactions = int(extracted_data.get(\"Digital Wallet Transactions\", 0))\n",
    "    if digital_wallet_transactions >= CONDITION_THRESHOLDS[\"Digital Wallet Transactions\"][\"min_transactions\"]:\n",
    "        total_score += CONDITION_THRESHOLDS[\"Digital Wallet Transactions\"][\"max_score\"]\n",
    "    \n",
    "    # Example: Cost of Living vs Spending\n",
    "    savings_ratio = float(extracted_data.get(\"Savings Ratio\", 0))\n",
    "    if savings_ratio >= CONDITION_THRESHOLDS[\"Cost of Living vs Spending\"][\"savings_ratio\"]:\n",
    "        total_score += CONDITION_THRESHOLDS[\"Cost of Living vs Spending\"][\"max_score\"]\n",
    "    \n",
    "    # Example: Annual Income or Turnover\n",
    "    annual_income = int(extracted_data.get(\"Annual Income\", 0))\n",
    "    if annual_income >= CONDITION_THRESHOLDS[\"Annual Income or Turnover\"][\"min_income\"]:\n",
    "        total_score += CONDITION_THRESHOLDS[\"Annual Income or Turnover\"][\"max_score\"]\n",
    "    \n",
    "    # Example: Fixed Deposit/Savings Investments\n",
    "    savings_investments = int(extracted_data.get(\"Fixed Deposit/Savings Investments\", 0))\n",
    "    if savings_investments >= CONDITION_THRESHOLDS[\"Fixed Deposit/Savings Investments\"][\"min_investment\"]:\n",
    "        total_score += CONDITION_THRESHOLDS[\"Fixed Deposit/Savings Investments\"][\"max_score\"]\n",
    "    \n",
    "    # Example: Assets of Individual/Family\n",
    "    assets = int(extracted_data.get(\"Assets\", 0))\n",
    "    if assets >= CONDITION_THRESHOLDS[\"Assets of Individual/Family\"][\"min_assets\"]:\n",
    "        total_score += CONDITION_THRESHOLDS[\"Assets of Individual/Family\"][\"max_score\"]\n",
    "    \n",
    "    # Example: Bank Balance & Multiple Accounts\n",
    "    bank_balance = int(extracted_data.get(\"Bank Balance\", 0))\n",
    "    if bank_balance >= CONDITION_THRESHOLDS[\"Bank Balance & Multiple Accounts\"][\"min_balance\"]:\n",
    "        total_score += CONDITION_THRESHOLDS[\"Bank Balance & Multiple Accounts\"][\"max_score\"]\n",
    "    \n",
    "    # Example: Entrepreneur Length of Employment\n",
    "    employment_years = int(extracted_data.get(\"Entrepreneur Length of Employment\", 0))\n",
    "    if employment_years >= CONDITION_THRESHOLDS[\"Entrepreneur Length of Employment\"][\"min_years\"]:\n",
    "        total_score += CONDITION_THRESHOLDS[\"Entrepreneur Length of Employment\"][\"max_score\"]\n",
    "    \n",
    "    # Example: ESG Related Information\n",
    "    esg_initiatives = int(extracted_data.get(\"ESG Initiatives\", 0))\n",
    "    if esg_initiatives >= CONDITION_THRESHOLDS[\"ESG Related Information\"][\"min_initiatives\"]:\n",
    "        total_score += CONDITION_THRESHOLDS[\"ESG Related Information\"][\"max_score\"]\n",
    "    \n",
    "    return total_score\n",
    "\n",
    "# Main function to process the file\n",
    "def process_file(file_path, template):\n",
    "    # Check file type and extract text\n",
    "    if file_path.endswith('.docx'):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith('.pdf'):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please upload a DOCX or PDF file.\")\n",
    "    \n",
    "    # Validate the content before proceeding\n",
    "    if not validate_content(text):\n",
    "        raise ValueError(\"The uploaded file does not contain relevant financial or ESG-related information.\")\n",
    "    \n",
    "    # Extract information using Groq API\n",
    "    extracted_data = extract_information_with_groq(text, template)\n",
    "    \n",
    "    # Calculate total score\n",
    "    total_score = calculate_score(extracted_data)\n",
    "    \n",
    "    # Determine loan eligibility\n",
    "    if total_score >= 8:\n",
    "        return f\"Loan Approved! Total Score: {total_score}/10\"\n",
    "    else:\n",
    "        return f\"Loan Rejected. Total Score: {total_score}/10\"\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the comprehensive template\n",
    "    template = \"\"\"\n",
    "    ### 1. Personal/Company Information\n",
    "    - **Name**: [Insert Name]\n",
    "    - **Organization**: [Insert Organization Name]\n",
    "    - **Industry**: [Insert Industry Type]\n",
    "\n",
    "    ### 2. Credit Information\n",
    "    - **CIBIL Score**: [Insert CIBIL Score]\n",
    "      - **Description**: [Brief description or notes about the score]\n",
    "\n",
    "    ... (rest of the template)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Path to the uploaded file (DOCX or PDF)\n",
    "    file_path = \"/home/dharun/Desktop/llama/A Personalized Approach to Post-Traumatic Stress Disorder 1 (1) (1).pdf\"\n",
    "    \n",
    "    # Process the file and determine loan eligibility\n",
    "    try:\n",
    "        result = process_file(file_path, template)\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The uploaded file does not contain relevant financial or ESG-related information.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "\n",
    "# Initialize Groq client with your API key\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "# Define the list of valid keywords/phrases based on your categories\n",
    "VALID_KEYWORDS = [\n",
    "    \"CIBIL Score\", \"Overdue\", \"Pending Loans\", \"Utility Payments\", \n",
    "    \"Electricity Bill\", \"Water Bill\", \"Digital Wallet\", \"Cost of Living\", \n",
    "    \"Annual Income\", \"Turnover\", \"Fixed Deposit\", \"Savings Investments\", \n",
    "    \"Assets\", \"Bank Balance\", \"Entrepreneur\", \"ESG\", \"Environmental Impact\", \n",
    "    \"Social Responsibility\", \"Governance\"\n",
    "]\n",
    "\n",
    "# Define thresholds for each condition\n",
    "CONDITION_THRESHOLDS = {\n",
    "    \"CIBIL Score\": {\"max_score\": 2, \"good_threshold\": 750},\n",
    "    \"Overdue/Pending Loans\": {\"max_score\": 2, \"max_overdue\": 50000},\n",
    "    \"Utility Payments\": {\"max_score\": 1, \"on_time_ratio\": 0.9},\n",
    "    \"Digital Wallet Transactions\": {\"max_score\": 1, \"min_transactions\": 5},\n",
    "    \"Cost of Living vs Spending\": {\"max_score\": 1, \"savings_ratio\": 0.2},\n",
    "    \"Annual Income or Turnover\": {\"max_score\": 2, \"min_income\": 500000},\n",
    "    \"Fixed Deposit/Savings Investments\": {\"max_score\": 1, \"min_investment\": 100000},\n",
    "    \"Assets of Individual/Family\": {\"max_score\": 1, \"min_assets\": 500000},\n",
    "    \"Bank Balance & Multiple Accounts\": {\"max_score\": 1, \"min_balance\": 100000},\n",
    "    \"Entrepreneur Length of Employment\": {\"max_score\": 1, \"min_years\": 2},\n",
    "    \"ESG Related Information\": {\"max_score\": 1, \"min_initiatives\": 1}\n",
    "}\n",
    "\n",
    "# Function to extract text from DOCX\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        full_text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            full_text += page.extract_text()\n",
    "    return full_text\n",
    "\n",
    "# Function to validate content based on keywords\n",
    "def validate_content(text):\n",
    "    # Check if any of the valid keywords are present in the text\n",
    "    for keyword in VALID_KEYWORDS:\n",
    "        if keyword.lower() in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to extract information using Groq API\n",
    "def extract_information_with_groq(text, template):\n",
    "    # Prepare the prompt for Groq API\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with extracting financial and ESG-related information from the following text.\n",
    "    Use the provided template to structure the output. Fill in the fields based on the content of the text.\n",
    "    \n",
    "    Template:\n",
    "    {template}\n",
    "    \n",
    "    Text to analyze:\n",
    "    {text}\n",
    "    \n",
    "    Output the filled template with the extracted information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call Groq API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts structured information from unstructured text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_completion_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )\n",
    "    \n",
    "    # Stream the response and parse it into a dictionary\n",
    "    extracted_info = {}\n",
    "    current_key = None\n",
    "    for chunk in completion:\n",
    "        content = chunk.choices[0].delta.content or \"\"\n",
    "        lines = content.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if line.strip().endswith(\":\"):\n",
    "                # This is a key (e.g., \"CIBIL Score:\")\n",
    "                current_key = line.strip().rstrip(\":\")\n",
    "                extracted_info[current_key] = \"\"\n",
    "            elif current_key:\n",
    "                # This is a value for the current key\n",
    "                extracted_info[current_key] += line.strip()\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "# Function to calculate score and adjust threshold dynamically\n",
    "def calculate_score_and_adjust_threshold(extracted_data, original_threshold=8):\n",
    "    total_score = 0\n",
    "    max_possible_score = 0\n",
    "    missing_conditions = []\n",
    "\n",
    "    # Example: CIBIL Score\n",
    "    cibil_score = int(extracted_data.get(\"CIBIL Score\", 0))\n",
    "    if cibil_score > 0:\n",
    "        max_possible_score += CONDITION_THRESHOLDS[\"CIBIL Score\"][\"max_score\"]\n",
    "        if cibil_score >= CONDITION_THRESHOLDS[\"CIBIL Score\"][\"good_threshold\"]:\n",
    "            total_score += CONDITION_THRESHOLDS[\"CIBIL Score\"][\"max_score\"]\n",
    "    else:\n",
    "        missing_conditions.append(\"CIBIL Score\")\n",
    "\n",
    "    # Example: Overdue/Pending Loans\n",
    "    overdue_loans = int(extracted_data.get(\"Overdue/Pending Loans\", 0))\n",
    "    if overdue_loans > 0:\n",
    "        max_possible_score += CONDITION_THRESHOLDS[\"Overdue/Pending Loans\"][\"max_score\"]\n",
    "        if overdue_loans <= CONDITION_THRESHOLDS[\"Overdue/Pending Loans\"][\"max_overdue\"]:\n",
    "            total_score += CONDITION_THRESHOLDS[\"Overdue/Pending Loans\"][\"max_score\"]\n",
    "    else:\n",
    "        missing_conditions.append(\"Overdue/Pending Loans\")\n",
    "\n",
    "    # Repeat similar logic for other conditions...\n",
    "\n",
    "    # Adjust the threshold based on missing conditions\n",
    "    num_conditions = len(CONDITION_THRESHOLDS)\n",
    "    num_missing = len(missing_conditions)\n",
    "    adjusted_threshold = original_threshold * (num_conditions - num_missing) / num_conditions\n",
    "\n",
    "    return total_score, adjusted_threshold, missing_conditions\n",
    "\n",
    "\n",
    "# Main function to process the file\n",
    "def process_file(file_path, template):\n",
    "    # Check file type and extract text\n",
    "    if file_path.endswith('.docx'):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith('.pdf'):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please upload a DOCX or PDF file.\")\n",
    "    \n",
    "    # Validate the content before proceeding\n",
    "    if not validate_content(text):\n",
    "        raise ValueError(\"The uploaded file does not contain relevant financial or ESG-related information.\")\n",
    "    \n",
    "    # Extract information using Groq API\n",
    "    extracted_data = extract_information_with_groq(text, template)\n",
    "    \n",
    "    # Calculate total score and adjust threshold\n",
    "    total_score, adjusted_threshold, missing_conditions = calculate_score_and_adjust_threshold(extracted_data)\n",
    "    \n",
    "    # Determine loan eligibility based on 75% of the original threshold\n",
    "    original_threshold = 8\n",
    "    minimum_required_threshold = original_threshold * 0.75\n",
    "    \n",
    "    if total_score >= minimum_required_threshold:\n",
    "        return \"You are eligible for a loan! Our bank will reach you shortly.\"\n",
    "    else:\n",
    "        rejection_reason = (\n",
    "            f\"Loan Rejected. Total Score: {total_score}/{adjusted_threshold:.1f}\\n\"\n",
    "            f\"The following conditions were missing: {', '.join(missing_conditions)}.\\n\"\n",
    "            f\"Your score did not meet the minimum required threshold of {minimum_required_threshold:.1f}.\"\n",
    "        )\n",
    "        return rejection_reason\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the comprehensive template\n",
    "    template = \"\"\"\n",
    "    ### 1. Personal/Company Information\n",
    "    - **Name**: [Insert Name]\n",
    "    - **Organization**: [Insert Organization Name]\n",
    "    - **Industry**: [Insert Industry Type]\n",
    "\n",
    "    ### 2. Credit Information\n",
    "    - **CIBIL Score**: [Insert CIBIL Score]\n",
    "      - **Description**: [Brief description or notes about the score]\n",
    "\n",
    "    ... (rest of the template)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Path to the uploaded file (DOCX or PDF)\n",
    "    file_path = \"/home/dharun/Desktop/llama/A Personalized Approach to Post-Traumatic Stress Disorder 1 (1) (1).pdf\"\n",
    "    \n",
    "    # Process the file and determine loan eligibility\n",
    "    try:\n",
    "        result = process_file(file_path, template)\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.3-70b-versatile` in organization `org_01jmaafhskfcf8tc0wcg2fcaz1` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 13127, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "\n",
    "# Initialize Groq client with your API key\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "# Define thresholds for each condition\n",
    "CONDITION_THRESHOLDS = {\n",
    "    \"CIBIL Score\": {\"max_score\": 2, \"good_threshold\": 750},\n",
    "    \"Overdue/Pending Loans\": {\"max_score\": 2, \"max_overdue\": 50000},\n",
    "    \"Utility Payments\": {\"max_score\": 1, \"on_time_ratio\": 0.9},\n",
    "    \"Digital Wallet Transactions\": {\"max_score\": 1, \"min_transactions\": 5},\n",
    "    \"Cost of Living vs Spending\": {\"max_score\": 1, \"savings_ratio\": 0.2},\n",
    "    \"Annual Income or Turnover\": {\"max_score\": 2, \"min_income\": 500000},\n",
    "    \"Fixed Deposit/Savings Investments\": {\"max_score\": 1, \"min_investment\": 100000},\n",
    "    \"Assets of Individual/Family\": {\"max_score\": 1, \"min_assets\": 500000},\n",
    "    \"Bank Balance & Multiple Accounts\": {\"max_score\": 1, \"min_balance\": 100000},\n",
    "    \"Entrepreneur Length of Employment\": {\"max_score\": 1, \"min_years\": 2},\n",
    "    \"ESG Related Information\": {\"max_score\": 1, \"min_initiatives\": 1}\n",
    "}\n",
    "\n",
    "# Function to extract text from DOCX\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        full_text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            full_text += page.extract_text()\n",
    "    return full_text\n",
    "\n",
    "# Function to extract information using Groq API\n",
    "def extract_information_with_groq(text):\n",
    "    # Prepare the prompt for Groq API\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with extracting financial and ESG-related information from the following text.\n",
    "    Identify and extract the following fields if they are present in the text:\n",
    "    - CIBIL Score\n",
    "    - Overdue/Pending Loans\n",
    "    - Utility Payments (On-Time Ratio)\n",
    "    - Digital Wallet Transactions\n",
    "    - Cost of Living vs Spending (Savings Ratio)\n",
    "    - Annual Income or Turnover\n",
    "    - Fixed Deposit/Savings Investments\n",
    "    - Assets of Individual/Family\n",
    "    - Bank Balance & Multiple Accounts\n",
    "    - Entrepreneur Length of Employment\n",
    "    - ESG Related Information (Number of Initiatives)\n",
    "    \n",
    "    Text to analyze:\n",
    "    {text}\n",
    "    \n",
    "    Output the extracted information in the format: Field: Value\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call Groq API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts structured information from unstructured text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_completion_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )\n",
    "    \n",
    "    # Stream the response and parse it into a dictionary\n",
    "    extracted_info = {}\n",
    "    current_key = None\n",
    "    for chunk in completion:\n",
    "        content = chunk.choices[0].delta.content or \"\"\n",
    "        lines = content.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                extracted_info[key.strip()] = value.strip()\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "# Function to calculate score and adjust threshold dynamically\n",
    "def calculate_score_and_adjust_threshold(extracted_data, original_threshold=8):\n",
    "    total_score = 0\n",
    "    max_possible_score = 0\n",
    "    missing_conditions = []\n",
    "\n",
    "    # Example: CIBIL Score\n",
    "    cibil_score = int(extracted_data.get(\"CIBIL Score\", 0))\n",
    "    if cibil_score > 0:\n",
    "        max_possible_score += CONDITION_THRESHOLDS[\"CIBIL Score\"][\"max_score\"]\n",
    "        if cibil_score >= CONDITION_THRESHOLDS[\"CIBIL Score\"][\"good_threshold\"]:\n",
    "            total_score += CONDITION_THRESHOLDS[\"CIBIL Score\"][\"max_score\"]\n",
    "    else:\n",
    "        missing_conditions.append(\"CIBIL Score\")\n",
    "\n",
    "    # Example: Overdue/Pending Loans\n",
    "    overdue_loans = int(extracted_data.get(\"Overdue/Pending Loans\", 0))\n",
    "    if overdue_loans > 0:\n",
    "        max_possible_score += CONDITION_THRESHOLDS[\"Overdue/Pending Loans\"][\"max_score\"]\n",
    "        if overdue_loans <= CONDITION_THRESHOLDS[\"Overdue/Pending Loans\"][\"max_overdue\"]:\n",
    "            total_score += CONDITION_THRESHOLDS[\"Overdue/Pending Loans\"][\"max_score\"]\n",
    "    else:\n",
    "        missing_conditions.append(\"Overdue/Pending Loans\")\n",
    "\n",
    "    # Repeat similar logic for other conditions...\n",
    "\n",
    "    # Adjust the threshold based on missing conditions\n",
    "    num_conditions = len(CONDITION_THRESHOLDS)\n",
    "    num_missing = len(missing_conditions)\n",
    "    adjusted_threshold = original_threshold * (num_conditions - num_missing) / num_conditions\n",
    "\n",
    "    return total_score, adjusted_threshold, missing_conditions\n",
    "\n",
    "\n",
    "# Main function to process the file\n",
    "def process_file(file_path):\n",
    "    # Check file type and extract text\n",
    "    if file_path.endswith('.docx'):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith('.pdf'):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please upload a DOCX or PDF file.\")\n",
    "    \n",
    "    # Extract information using Groq API\n",
    "    extracted_data = extract_information_with_groq(text)\n",
    "    \n",
    "    # Calculate total score and adjust threshold\n",
    "    total_score, adjusted_threshold, missing_conditions = calculate_score_and_adjust_threshold(extracted_data)\n",
    "    \n",
    "    # Determine loan eligibility based on 75% of the original threshold\n",
    "    original_threshold = 8\n",
    "    minimum_required_threshold = original_threshold * 0.75\n",
    "    \n",
    "    if total_score >= minimum_required_threshold:\n",
    "        return \"You are eligible for a loan! Our bank will reach you shortly.\"\n",
    "    else:\n",
    "        rejection_reason = (\n",
    "            f\"Loan Rejected. Total Score: {total_score}/{adjusted_threshold:.1f}\\n\"\n",
    "            f\"The following conditions were missing: {', '.join(missing_conditions)}.\\n\"\n",
    "            f\"Your score did not meet the minimum required threshold of {minimum_required_threshold:.1f}.\"\n",
    "        )\n",
    "        return rejection_reason\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the uploaded file (DOCX or PDF)\n",
    "    file_path = \"/home/dharun/Desktop/llama/A Personalized Approach to Post-Traumatic Stress Disorder 1 (1) (1).pdf\"\n",
    "    \n",
    "    # Process the file and determine loan eligibility\n",
    "    try:\n",
    "        result = process_file(file_path)\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan Rejected. Total Score: 0/6.5\n",
      "The following conditions were missing: CIBIL Score, Overdue/Pending Loans.\n",
      "Your score did not meet the minimum required threshold of 6.0.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "\n",
    "# Initialize Groq client with your API key\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "# Define thresholds for each condition\n",
    "CONDITION_THRESHOLDS = {\n",
    "    \"CIBIL Score\": {\"max_score\": 2, \"good_threshold\": 750},\n",
    "    \"Overdue/Pending Loans\": {\"max_score\": 2, \"max_overdue\": 50000},\n",
    "    \"Utility Payments\": {\"max_score\": 1, \"on_time_ratio\": 0.9},\n",
    "    \"Digital Wallet Transactions\": {\"max_score\": 1, \"min_transactions\": 5},\n",
    "    \"Cost of Living vs Spending\": {\"max_score\": 1, \"savings_ratio\": 0.2},\n",
    "    \"Annual Income or Turnover\": {\"max_score\": 2, \"min_income\": 500000},\n",
    "    \"Fixed Deposit/Savings Investments\": {\"max_score\": 1, \"min_investment\": 100000},\n",
    "    \"Assets of Individual/Family\": {\"max_score\": 1, \"min_assets\": 500000},\n",
    "    \"Bank Balance & Multiple Accounts\": {\"max_score\": 1, \"min_balance\": 100000},\n",
    "    \"Entrepreneur Length of Employment\": {\"max_score\": 1, \"min_years\": 2},\n",
    "    \"ESG Related Information\": {\"max_score\": 1, \"min_initiatives\": 1}\n",
    "}\n",
    "\n",
    "# Function to extract text from DOCX\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        full_text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            full_text += page.extract_text()\n",
    "    return full_text\n",
    "\n",
    "# Function to extract information using Groq API\n",
    "def extract_information_with_groq(text):\n",
    "    # Prepare the prompt for Groq API\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with extracting financial and ESG-related information from the following text.\n",
    "    Identify and extract the following fields if they are present in the text:\n",
    "    - CIBIL Score\n",
    "    - Overdue/Pending Loans\n",
    "    - Utility Payments (On-Time Ratio)\n",
    "    - Digital Wallet Transactions\n",
    "    - Cost of Living vs Spending (Savings Ratio)\n",
    "    - Annual Income or Turnover\n",
    "    - Fixed Deposit/Savings Investments\n",
    "    - Assets of Individual/Family\n",
    "    - Bank Balance & Multiple Accounts\n",
    "    - Entrepreneur Length of Employment\n",
    "    - ESG Related Information (Number of Initiatives)\n",
    "    \n",
    "    Text to analyze:\n",
    "    {text}\n",
    "    \n",
    "    Output the extracted information in the format: Field: Value\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call Groq API with updated parameters\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-2.5-32b\",  # Updated model name\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts structured information from unstructured text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.6,  # Adjusted temperature\n",
    "        max_completion_tokens=4096,  # Increased max tokens\n",
    "        top_p=0.95,  # Adjusted top_p\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )\n",
    "    \n",
    "    # Stream the response and parse it into a dictionary\n",
    "    extracted_info = {}\n",
    "    current_key = None\n",
    "    for chunk in completion:\n",
    "        content = chunk.choices[0].delta.content or \"\"\n",
    "        lines = content.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                extracted_info[key.strip()] = value.strip()\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "# Function to calculate score and adjust threshold dynamically\n",
    "def calculate_score_and_adjust_threshold(extracted_data, original_threshold=8):\n",
    "    total_score = 0\n",
    "    max_possible_score = 0\n",
    "    missing_conditions = []\n",
    "\n",
    "    # Example: CIBIL Score\n",
    "    cibil_score = int(extracted_data.get(\"CIBIL Score\", 0))\n",
    "    if cibil_score > 0:\n",
    "        max_possible_score += CONDITION_THRESHOLDS[\"CIBIL Score\"][\"max_score\"]\n",
    "        if cibil_score >= CONDITION_THRESHOLDS[\"CIBIL Score\"][\"good_threshold\"]:\n",
    "            total_score += CONDITION_THRESHOLDS[\"CIBIL Score\"][\"max_score\"]\n",
    "    else:\n",
    "        missing_conditions.append(\"CIBIL Score\")\n",
    "\n",
    "    # Example: Overdue/Pending Loans\n",
    "    overdue_loans = int(extracted_data.get(\"Overdue/Pending Loans\", 0))\n",
    "    if overdue_loans > 0:\n",
    "        max_possible_score += CONDITION_THRESHOLDS[\"Overdue/Pending Loans\"][\"max_score\"]\n",
    "        if overdue_loans <= CONDITION_THRESHOLDS[\"Overdue/Pending Loans\"][\"max_overdue\"]:\n",
    "            total_score += CONDITION_THRESHOLDS[\"Overdue/Pending Loans\"][\"max_score\"]\n",
    "    else:\n",
    "        missing_conditions.append(\"Overdue/Pending Loans\")\n",
    "\n",
    "    # Repeat similar logic for other conditions...\n",
    "\n",
    "    # Adjust the threshold based on missing conditions\n",
    "    num_conditions = len(CONDITION_THRESHOLDS)\n",
    "    num_missing = len(missing_conditions)\n",
    "    adjusted_threshold = original_threshold * (num_conditions - num_missing) / num_conditions\n",
    "\n",
    "    return total_score, adjusted_threshold, missing_conditions\n",
    "\n",
    "\n",
    "# Main function to process the file\n",
    "def process_file(file_path):\n",
    "    # Check file type and extract text\n",
    "    if file_path.endswith('.docx'):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith('.pdf'):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please upload a DOCX or PDF file.\")\n",
    "    \n",
    "    # Extract information using Groq API\n",
    "    extracted_data = extract_information_with_groq(text)\n",
    "    \n",
    "    # Calculate total score and adjust threshold\n",
    "    total_score, adjusted_threshold, missing_conditions = calculate_score_and_adjust_threshold(extracted_data)\n",
    "    \n",
    "    # Determine loan eligibility based on 75% of the original threshold\n",
    "    original_threshold = 8\n",
    "    minimum_required_threshold = original_threshold * 0.75\n",
    "    \n",
    "    if total_score >= minimum_required_threshold:\n",
    "        return \"You are eligible for a loan! Our bank will reach you shortly.\"\n",
    "    else:\n",
    "        rejection_reason = (\n",
    "            f\"Loan Rejected. Total Score: {total_score}/{adjusted_threshold:.1f}\\n\"\n",
    "            f\"The following conditions were missing: {', '.join(missing_conditions)}.\\n\"\n",
    "            f\"Your score did not meet the minimum required threshold of {minimum_required_threshold:.1f}.\"\n",
    "        )\n",
    "        return rejection_reason\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the uploaded file (DOCX or PDF)\n",
    "    file_path = \"/home/dharun/Desktop/llama/temp.pdf\"\n",
    "    \n",
    "    # Process the file and determine loan eligibility\n",
    "    try:\n",
    "        result = process_file(file_path)\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're sorry, but your application does not meet the requirements.\n",
      "Total Score: 1/1.0\n",
      "The following conditions were missing: CIBIL Score, Annual Income or Turnover, Bank Balance & Multiple Accounts, Utility Payments.\n",
      "To qualify, aim to improve these areas.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "\n",
    "# Initialize Groq client with your API key\n",
    "client = Groq(api_key=\"\")\n",
    "\n",
    "# Define simplified thresholds for each condition\n",
    "CONDITION_THRESHOLDS = {\n",
    "    \"CIBIL Score\": {\"max_score\": 1, \"good_threshold\": 600},  # Relaxed threshold\n",
    "    \"Annual Income or Turnover\": {\"max_score\": 1, \"min_income\": 300000},  # Lower income requirement\n",
    "    \"Bank Balance & Multiple Accounts\": {\"max_score\": 1, \"min_balance\": 50000},  # Lower balance requirement\n",
    "    \"Utility Payments\": {\"max_score\": 1, \"on_time_ratio\": 0.7},  # Relaxed payment history\n",
    "    \"ESG Related Information\": {\"max_score\": 1, \"min_initiatives\": 0}  # Optional ESG initiatives\n",
    "}\n",
    "\n",
    "# Function to extract text from DOCX\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        full_text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            full_text += page.extract_text()\n",
    "    return full_text\n",
    "\n",
    "# Function to extract information using Groq API\n",
    "def extract_information_with_groq(text):\n",
    "    # Prepare the prompt for Groq API\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with extracting financial and ESG-related information from the following text.\n",
    "    Identify and extract the following fields if they are present in the text:\n",
    "    - CIBIL Score\n",
    "    - Annual Income or Turnover\n",
    "    - Bank Balance & Multiple Accounts\n",
    "    - Utility Payments (On-Time Ratio)\n",
    "    - ESG Related Information (Number of Initiatives)\n",
    "    \n",
    "    Text to analyze:\n",
    "    {text}\n",
    "    \n",
    "    Output the extracted information in the format: Field: Value\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call Groq API with updated parameters\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-2.5-32b\",  # Updated model name\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts structured information from unstructured text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.6,  # Adjusted temperature\n",
    "        max_completion_tokens=4096,  # Increased max tokens\n",
    "        top_p=0.95,  # Adjusted top_p\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )\n",
    "    \n",
    "    # Stream the response and parse it into a dictionary\n",
    "    extracted_info = {}\n",
    "    current_key = None\n",
    "    for chunk in completion:\n",
    "        content = chunk.choices[0].delta.content or \"\"\n",
    "        lines = content.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                extracted_info[key.strip()] = value.strip()\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "# Function to calculate score and adjust threshold dynamically\n",
    "def calculate_score_and_adjust_threshold(extracted_data, original_threshold=5):\n",
    "    total_score = 0\n",
    "    missing_conditions = []\n",
    "\n",
    "    # Example: CIBIL Score\n",
    "    cibil_score = int(extracted_data.get(\"CIBIL Score\", 0))\n",
    "    if cibil_score > 0:\n",
    "        if cibil_score >= CONDITION_THRESHOLDS[\"CIBIL Score\"][\"good_threshold\"]:\n",
    "            total_score += CONDITION_THRESHOLDS[\"CIBIL Score\"][\"max_score\"]\n",
    "    else:\n",
    "        missing_conditions.append(\"CIBIL Score\")\n",
    "\n",
    "    # Example: Annual Income or Turnover\n",
    "    annual_income = int(extracted_data.get(\"Annual Income or Turnover\", 0))\n",
    "    if annual_income > 0:\n",
    "        if annual_income >= CONDITION_THRESHOLDS[\"Annual Income or Turnover\"][\"min_income\"]:\n",
    "            total_score += CONDITION_THRESHOLDS[\"Annual Income or Turnover\"][\"max_score\"]\n",
    "    else:\n",
    "        missing_conditions.append(\"Annual Income or Turnover\")\n",
    "\n",
    "    # Example: Bank Balance & Multiple Accounts\n",
    "    bank_balance = int(extracted_data.get(\"Bank Balance & Multiple Accounts\", 0))\n",
    "    if bank_balance > 0:\n",
    "        if bank_balance >= CONDITION_THRESHOLDS[\"Bank Balance & Multiple Accounts\"][\"min_balance\"]:\n",
    "            total_score += CONDITION_THRESHOLDS[\"Bank Balance & Multiple Accounts\"][\"max_score\"]\n",
    "    else:\n",
    "        missing_conditions.append(\"Bank Balance & Multiple Accounts\")\n",
    "\n",
    "    # Example: Utility Payments\n",
    "    utility_payment_ratio = float(extracted_data.get(\"Utility Payments\", 0))\n",
    "    if utility_payment_ratio > 0:\n",
    "        if utility_payment_ratio >= CONDITION_THRESHOLDS[\"Utility Payments\"][\"on_time_ratio\"]:\n",
    "            total_score += CONDITION_THRESHOLDS[\"Utility Payments\"][\"max_score\"]\n",
    "    else:\n",
    "        missing_conditions.append(\"Utility Payments\")\n",
    "\n",
    "    # Example: ESG Related Information\n",
    "    esg_initiatives = int(extracted_data.get(\"ESG Related Information\", 0))\n",
    "    if esg_initiatives >= CONDITION_THRESHOLDS[\"ESG Related Information\"][\"min_initiatives\"]:\n",
    "        total_score += CONDITION_THRESHOLDS[\"ESG Related Information\"][\"max_score\"]\n",
    "\n",
    "    # Adjust the threshold based on missing conditions\n",
    "    num_conditions = len(CONDITION_THRESHOLDS)\n",
    "    num_missing = len(missing_conditions)\n",
    "    adjusted_threshold = original_threshold * (num_conditions - num_missing) / num_conditions\n",
    "\n",
    "    return total_score, adjusted_threshold, missing_conditions\n",
    "\n",
    "\n",
    "# Main function to process the file\n",
    "def process_file(file_path):\n",
    "    # Check file type and extract text\n",
    "    if file_path.endswith('.docx'):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith('.pdf'):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please upload a DOCX or PDF file.\")\n",
    "    \n",
    "    # Extract information using Groq API\n",
    "    extracted_data = extract_information_with_groq(text)\n",
    "    \n",
    "    # Calculate total score and adjust threshold\n",
    "    total_score, adjusted_threshold, missing_conditions = calculate_score_and_adjust_threshold(extracted_data)\n",
    "    \n",
    "    # Determine loan eligibility based on relaxed threshold\n",
    "    original_threshold = 5  # Reduced threshold\n",
    "    minimum_required_threshold = original_threshold * 0.75\n",
    "    \n",
    "    if total_score >= minimum_required_threshold:\n",
    "        return \"Great news! You are eligible for a loan. Our team will contact you soon.\"\n",
    "    else:\n",
    "        rejection_reason = (\n",
    "            f\"We're sorry, but your application does not meet the requirements.\\n\"\n",
    "            f\"Total Score: {total_score}/{adjusted_threshold:.1f}\\n\"\n",
    "            f\"The following conditions were missing: {', '.join(missing_conditions)}.\\n\"\n",
    "            f\"To qualify, aim to improve these areas.\"\n",
    "        )\n",
    "        return rejection_reason\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the uploaded file (DOCX or PDF)\n",
    "    file_path = \"/home/dharun/Desktop/llama/temp.pdf\"\n",
    "    \n",
    "    # Process the file and determine loan eligibility\n",
    "    try:\n",
    "        result = process_file(file_path)\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
